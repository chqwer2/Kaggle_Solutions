{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.016063,"end_time":"2023-02-06T12:29:18.479831","exception":false,"start_time":"2023-02-06T12:29:18.463768","status":"completed"},"tags":[]},"source":["## Requirements"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-02-07T11:57:22.888198Z","iopub.status.busy":"2023-02-07T11:57:22.887004Z","iopub.status.idle":"2023-02-07T11:58:35.311699Z","shell.execute_reply":"2023-02-07T11:58:35.310499Z","shell.execute_reply.started":"2023-02-07T11:57:22.888068Z"},"papermill":{"duration":66.474137,"end_time":"2023-02-06T12:30:24.982634","exception":false,"start_time":"2023-02-06T12:29:18.508497","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["!pip install -q albumentations==1.2.1 --no-index --find-links=/home/br/workspace/RSNA2023/input/rsna-bc-pip-requirements\n","!pip install -q pylibjpeg-libjpeg==1.3.1 --no-index --find-links=/home/br/workspace/RSNA2023/input/rsna-bc-pip-requirements\n","!pip install -q pydicom==2.0.0 --no-index --find-links=/home/br/workspace/RSNA2023/input/rsna-bc-pip-requirements\n","!pip install -q python-gdcm==3.0.20 --no-index --find-links=/home/br/workspace/RSNA2023/input/rsna-bc-pip-requirements\n","!pip install -q dicomsdl==0.109.1 --no-index --find-links=/home/br/workspace/RSNA2023/input/rsna-bc-pip-requirements\n","\n","# dali\n","!pip install -q /home/br/workspace/RSNA2023/input/nvidia-dali-nightly-cuda110-1230dev/nvidia_dali_nightly_cuda110-1.23.0.dev20230203-7187866-py3-none-manylinux2014_x86_64.whl"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" # Config"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","\n","IMG_SIZE = 1536\n","NBIT = 16"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T11:59:17.427599Z","iopub.status.busy":"2023-02-07T11:59:17.426625Z","iopub.status.idle":"2023-02-07T11:59:20.884110Z","shell.execute_reply":"2023-02-07T11:59:20.882899Z","shell.execute_reply.started":"2023-02-07T11:59:17.427556Z"},"papermill":{"duration":5.037552,"end_time":"2023-02-06T12:31:12.441309","exception":false,"start_time":"2023-02-06T12:31:07.403757","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import sys\n","sys.path.append(\"/home/br/workspace/RSNA2023/input/pytorch-image-models-main/\")\n","import timm\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os\n","from copy import copy\n","import gc\n","import shutil \n","\n","import glob\n","from scipy.special import expit\n","\n","import albumentations as A\n","import cv2\n","cv2.setNumThreads(0)\n","\n","import dicomsdl\n","import pydicom\n","from pydicom.filebase import DicomBytesIO\n","\n","from os.path import join\n","\n","from tqdm import tqdm\n","\n","from joblib import Parallel, delayed\n","import multiprocessing as mp\n","\n","from types import SimpleNamespace\n","from typing import Any, Dict\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import GradScaler, autocast\n","\n","\n","import nvidia.dali.fn as fn\n","import nvidia.dali.types as types\n","from nvidia.dali import pipeline_def\n","from nvidia.dali.types import DALIDataType\n","\n","\n","from nvidia.dali.backend import TensorGPU, TensorListGPU\n","from nvidia.dali.pipeline import Pipeline\n","import nvidia.dali.ops as ops\n","from nvidia.dali import types\n","from nvidia.dali.plugin.base_iterator import _DaliBaseIterator\n","from nvidia.dali.plugin.base_iterator import LastBatchPolicy\n","import torch\n","import torch.utils.dlpack as torch_dlpack\n","import ctypes\n","import numpy as np\n","import torch.nn.functional as F\n","import pydicom\n","\n","to_torch_type = {\n","    types.DALIDataType.FLOAT:   torch.float32,\n","    types.DALIDataType.FLOAT64: torch.float64,\n","    types.DALIDataType.FLOAT16: torch.float16,\n","    types.DALIDataType.UINT8:   torch.uint8,\n","    types.DALIDataType.INT8:    torch.int8,\n","    types.DALIDataType.UINT16:  torch.int16,\n","    types.DALIDataType.INT16:   torch.int16,\n","    types.DALIDataType.INT32:   torch.int32,\n","    types.DALIDataType.INT64:   torch.int64\n","}\n","\n","\n","def feed_ndarray(dali_tensor, arr, cuda_stream=None):\n","    \"\"\"\n","    Copy contents of DALI tensor to PyTorch's Tensor.\n","\n","    Parameters\n","    ----------\n","    `dali_tensor` : nvidia.dali.backend.TensorCPU or nvidia.dali.backend.TensorGPU\n","                    Tensor from which to copy\n","    `arr` : torch.Tensor\n","            Destination of the copy\n","    `cuda_stream` : torch.cuda.Stream, cudaStream_t or any value that can be cast to cudaStream_t.\n","                    CUDA stream to be used for the copy\n","                    (if not provided, an internal user stream will be selected)\n","                    In most cases, using pytorch's current stream is expected (for example,\n","                    if we are copying to a tensor allocated with torch.zeros(...))\n","    \"\"\"\n","    dali_type = to_torch_type[dali_tensor.dtype]\n","\n","    assert dali_type == arr.dtype, (\"The element type of DALI Tensor/TensorList\"\n","                                    \" doesn't match the element type of the target PyTorch Tensor: \"\n","                                    \"{} vs {}\".format(dali_type, arr.dtype))\n","    assert dali_tensor.shape() == list(arr.size()), \\\n","        (\"Shapes do not match: DALI tensor has size {0}, but PyTorch Tensor has size {1}\".\n","            format(dali_tensor.shape(), list(arr.size())))\n","    cuda_stream = types._raw_cuda_stream(cuda_stream)\n","\n","    # turn raw int to a c void pointer\n","    c_type_pointer = ctypes.c_void_p(arr.data_ptr())\n","    if isinstance(dali_tensor, (TensorGPU, TensorListGPU)):\n","        stream = None if cuda_stream is None else ctypes.c_void_p(cuda_stream)\n","        dali_tensor.copy_to_external(c_type_pointer, stream, non_blocking=True)\n","    else:\n","        dali_tensor.copy_to_external(c_type_pointer)\n","    return arr\n","\n","@pipeline_def\n","def jpg_decode_pipeline(jpgfiles):\n","    jpegs, _ = fn.readers.file(files=jpgfiles)\n","    images = fn.experimental.decoders.image(jpegs, device='mixed', output_type=types.ANY_DATA, dtype=DALIDataType.UINT16)\n","    return images\n","\n","def parse_window_element(elem):\n","    if type(elem)==list:\n","        return float(elem[0])\n","    if type(elem)==str:\n","        return float(elem)\n","    if type(elem)==float:\n","        return elem\n","    if type(elem)==pydicom.dataelem.DataElement:\n","        try:\n","            return float(elem[0])\n","        except:\n","            return float(elem.value)\n","    return None\n","\n","def linear_window(data, center, width):\n","    lower, upper = center - width // 2, center + width // 2\n","    data = torch.clamp(data, min=lower, max=upper)\n","    return data \n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.008037,"end_time":"2023-02-06T12:31:12.49277","exception":false,"start_time":"2023-02-06T12:31:12.484733","status":"completed"},"tags":[]},"source":["# Comp data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T11:59:20.921242Z","iopub.status.busy":"2023-02-07T11:59:20.918396Z","iopub.status.idle":"2023-02-07T11:59:21.125614Z","shell.execute_reply":"2023-02-07T11:59:21.124657Z","shell.execute_reply.started":"2023-02-07T11:59:20.921206Z"},"papermill":{"duration":0.23946,"end_time":"2023-02-06T12:31:12.740724","exception":false,"start_time":"2023-02-06T12:31:12.501264","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["DATA_FOLDER = '/home/br/workspace/RSNA2023/input/rsna-breast-cancer-detection/train_images/'\n","\n","test_df = pd.read_csv(f'/home/br/workspace/RSNA2023/input/rsna-breast-cancer-detection/train.csv')\n","test_df[\"fns\"] = test_df['patient_id'].astype(str) + '/' + test_df['image_id'].astype(str) + '.dcm'\n","test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T12:00:37.094767Z","iopub.status.busy":"2023-02-07T12:00:37.094051Z","iopub.status.idle":"2023-02-07T12:00:37.103055Z","shell.execute_reply":"2023-02-07T12:00:37.102019Z","shell.execute_reply.started":"2023-02-07T12:00:37.094727Z"},"trusted":true},"outputs":[],"source":["SAVE_SIZE = int(IMG_SIZE * 1.125)\n","SAVE_FOLDER = f\"/home/br/workspace/RSNA2023/input/images_gpugen/{IMG_SIZE}_{NBIT}bit/\"\n","os.makedirs(SAVE_FOLDER, exist_ok=True)\n","\n","N_CHUNKS = len(test_df[\"fns\"]) // 2000 if len(test_df[\"fns\"]) > 2000 else 1\n","CHUNKS = [(len(test_df[\"fns\"]) / N_CHUNKS * k, len(test_df[\"fns\"]) / N_CHUNKS * (k + 1)) for k in range(N_CHUNKS)]\n","CHUNKS = np.array(CHUNKS).astype(int)\n","JPG_FOLDER = f\"/home/br/workspace/RSNA2023/input/images_gpugen/{IMG_SIZE}jpg/\"\n","os.makedirs(JPG_FOLDER, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def convert_dicom_to_jpg(file, save_folder=\"\"):\n","    patient = file.split('/')[-2]\n","    image = file.split('/')[-1][:-4]\n","    dcmfile = pydicom.dcmread(file)\n","\n","    if dcmfile.file_meta.TransferSyntaxUID == '1.2.840.10008.1.2.4.90':\n","        with open(file, 'rb') as fp:\n","            raw = DicomBytesIO(fp.read())\n","            ds = pydicom.dcmread(raw)\n","        offset = ds.PixelData.find(b\"\\x00\\x00\\x00\\x0C\")  #<---- the jpeg2000 header info we're looking for\n","        hackedbitstream = bytearray()\n","        hackedbitstream.extend(ds.PixelData[offset:])\n","        with open(save_folder + f\"{patient}_{image}.jpg\", \"wb\") as binary_file:\n","            binary_file.write(hackedbitstream)\n","            \n","    if dcmfile.file_meta.TransferSyntaxUID == '1.2.840.10008.1.2.4.70':\n","        with open(file, 'rb') as fp:\n","            raw = DicomBytesIO(fp.read())\n","            ds = pydicom.dcmread(raw)\n","        offset = ds.PixelData.find(b\"\\xff\\xd8\\xff\\xe0\")  #<---- the jpeg lossless header info we're looking for\n","        hackedbitstream = bytearray()\n","        hackedbitstream.extend(ds.PixelData[offset:])\n","        with open(save_folder + f\"{patient}_{image}.jpg\", \"wb\") as binary_file:\n","            binary_file.write(hackedbitstream)\n","\n","\n","def process_dicom(img, dicom):\n","    try:\n","        invert = getattr(dicom, \"PhotometricInterpretation\", None) == \"MONOCHROME1\"\n","    except:\n","        invert = False\n","        \n","    center = parse_window_element(dicom[\"WindowCenter\"]) \n","    width = parse_window_element(dicom[\"WindowWidth\"])\n","        \n","    if (center is not None) & (width is not None):\n","        img = linear_window(img, center, width)\n","\n","    img = (img - img.min()) / (img.max() - img.min())\n","    if invert:\n","        img = 1 - img\n","    return img"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.008603,"end_time":"2023-02-06T12:31:12.818867","exception":false,"start_time":"2023-02-06T12:31:12.810264","status":"completed"},"tags":[]},"source":["## GPU Decoding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T12:00:40.268923Z","iopub.status.busy":"2023-02-07T12:00:40.268549Z"},"papermill":{"duration":102.364817,"end_time":"2023-02-06T12:32:55.317413","exception":false,"start_time":"2023-02-06T12:31:12.952596","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["n_workers = 4\n","for ttt, chunk in enumerate(CHUNKS):\n","    print(f'chunk {ttt} of {len(CHUNKS)} chunks')\n","    os.makedirs(JPG_FOLDER, exist_ok=True)\n","\n","    _ = Parallel(n_jobs=n_workers)(\n","        delayed(convert_dicom_to_jpg)(f'{DATA_FOLDER}/{img}', save_folder=JPG_FOLDER)\n","        for img in test_df[\"fns\"].tolist()[chunk[0]: chunk[1]]\n","    )\n","    \n","    jpgfiles = glob.glob(JPG_FOLDER + \"*.jpg\")\n","\n","    pipe = jpg_decode_pipeline(jpgfiles, batch_size=1, num_threads=n_workers, device_id=0)\n","    pipe.build()\n","\n","    for i, f in enumerate(tqdm(jpgfiles)):\n","        patient, dicom_id = f.split('/')[-1][:-4].split('_')\n","        dicom = pydicom.dcmread(DATA_FOLDER + f\"/{patient}/{dicom_id}.dcm\")\n","        try:\n","            out = pipe.run()\n","            # Dali -> Torch\n","            img = out[0][0]\n","            img_torch = torch.empty(img.shape(), dtype=torch.int16, device=\"cuda\")\n","            feed_ndarray(img, img_torch, cuda_stream=torch.cuda.current_stream(device=0))\n","            img = img_torch.float()\n","\n","            #apply dicom preprocessing\n","            img = process_dicom(img, dicom)\n","\n","            #resize the torch image\n","            img = F.interpolate(img.view(1, 1, img.size(0), img.size(1)), (SAVE_SIZE, SAVE_SIZE), mode=\"bilinear\")[0, 0]\n","\n","            if NBIT == 8:\n","                img = (img * 255).clip(0,255).to(torch.uint8).cpu().numpy() # 8 bit image\n","            elif NBIT == 16:\n","                img = (img * 65535).clip(0,65535).cpu().numpy().astype(np.uint16) # 16 bit image\n","            else:\n","                raise ValueError(f\"Unsupported NBIT value: {NBIT}\")\n","            \n","            out_file_name = SAVE_FOLDER + f\"{patient}_{dicom_id}.png\"\n","            cv2.imwrite(out_file_name, img)\n","    \n","        except Exception as e:\n","            print(i, e)\n","            pipe = jpg_decode_pipeline(jpgfiles[i+1:], batch_size=1, num_threads=n_workers, device_id=0)\n","            pipe.build()\n","            continue\n","\n","    shutil.rmtree(JPG_FOLDER)\n","    \n","fns = glob.glob(f'{SAVE_FOLDER}/*.png')\n","print(f'GPU Processed: {len(fns)}')"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.024386,"end_time":"2023-02-06T12:32:55.429853","exception":false,"start_time":"2023-02-06T12:32:55.405467","status":"completed"},"tags":[]},"source":["## CPU Decoding"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.039261,"end_time":"2023-02-06T12:32:55.495229","exception":false,"start_time":"2023-02-06T12:32:55.455968","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["gpu_processed_files = [fn.split('/')[-1].replace('_','/').replace('png','dcm') for fn in fns]\n","to_process = [f for f in test_df[\"fns\"].values if f not in gpu_processed_files]\n","print(f\"GPU processed files number: {len(gpu_processed_files)}, remain number: {len(to_process)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.037403,"end_time":"2023-02-06T12:32:55.557572","exception":false,"start_time":"2023-02-06T12:32:55.520169","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def process(f, save_folder=\"\"):\n","    patient = f.split('/')[-2]\n","    dicom_id = f.split('/')[-1][:-4]\n","    \n","    dicom = dicomsdl.open(f)\n","    img = dicom.pixelData()\n","    img = torch.from_numpy(img)\n","    img = process_dicom(img, dicom)\n","    \n","    img = F.interpolate(img.view(1, 1, img.size(0), img.size(1)), (SAVE_SIZE, SAVE_SIZE), mode=\"bilinear\")[0, 0]\n","\n","    ####\n","    if NBIT == 8:\n","        img = (img * 255).clip(0,255).to(torch.uint8).cpu().numpy() # 8 bit image\n","    elif NBIT == 16:\n","        img = (img * 65535).clip(0,65535).cpu().numpy().astype(np.uint16) # 16 bit image\n","    else:\n","        raise ValueError(f\"Unsupported NBIT value: {NBIT}\")\n","\n","    out_file_name = SAVE_FOLDER + f\"{patient}_{dicom_id}.png\"\n","    cv2.imwrite(out_file_name, img)\n","    return out_file_name"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.045144,"end_time":"2023-02-06T12:32:55.628204","exception":false,"start_time":"2023-02-06T12:32:55.58306","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["cpu_processed_filenames = Parallel(n_jobs=2)(\n","    delayed(process)(f'{DATA_FOLDER}/{img}', save_folder=SAVE_FOLDER)\n","    for img in tqdm(to_process)\n",")\n","cpu_processed_filenames = [f for f in cpu_processed_filenames if f]\n","print(f'CPU Raw image load complete with {len(cpu_processed_filenames)} loaded')"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.038085,"end_time":"2023-02-06T12:32:55.983371","exception":false,"start_time":"2023-02-06T12:32:55.945286","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["n_saved = len(glob.glob(f'{SAVE_FOLDER}/*.png'))\n","print(f'Image on disk count : {n_saved}')\n","print(f\"test_df length: {len(test_df)}\")\n","\n","gc.collect()\n","torch.cuda.empty_cache()\n","assert n_saved == len(test_df) == 54706"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# VINDR\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## vindr meta metadata"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tmp_dcm = pydicom.dcmread('/home/br/workspace/RSNA2023/input/extra_data/vindr/images/57ef58281d90655693cd34628e4c8083/480a3198d3c64bcfb5bb193702500f3f.dicom')\n","print(f\"file_meta.TransferSyntaxUID: {tmp_dcm.file_meta.TransferSyntaxUID}\")\n","print(fr\"jpeg2000 find:\", tmp_dcm.PixelData.find(b'\\x00\\x00\\x00\\x0C'))\n","print(fr\"jpeg lossless find:\", tmp_dcm.PixelData.find(b'\\xff\\xd8\\xff\\xe0'))\n","print(f\"PhotometricInterpretation: {getattr(tmp_dcm, 'PhotometricInterpretation', None)}\")\n","print(f\"WindowCenter: {parse_window_element(tmp_dcm['WindowCenter'])}\")\n","print(f\"WindowWidth: {parse_window_element(tmp_dcm['WindowWidth'])}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["transfersyntaxuids = []\n","jpeg2000s = []\n","jpeglosslesss = []\n","photometricinterpretations = []\n","windowcenters = []\n","windowwidths = []\n","for path in test_df[\"fns\"]:\n","    dcm = pydicom.dcmread(f'{DATA_FOLDER}/{path}')\n","    transfersyntaxuids.append(dcm.file_meta.TransferSyntaxUID)\n","    jpeg2000s.append(dcm.PixelData.find(b'\\x00\\x00\\x00\\x0C'))\n","    jpeglosslesss.append(dcm.PixelData.find(b'\\xff\\xd8\\xff\\xe0'))\n","    photometricinterpretations.append(getattr(dcm, 'PhotometricInterpretation', None))\n","    windowcenters.append(parse_window_element(dcm['WindowCenter']))\n","    windowwidths.append(parse_window_element(dcm['WindowWidth']))\n","\n","print(f\"len(transfersyntaxuids): {len(transfersyntaxuids)}; len(jpeg2000s): {len(jpeg2000s)}; \\\n","        len(jpeglosslesss): {len(jpeglosslesss)}; len(photometricinterpretations): {len(photometricinterpretations)}; \\\n","        len(windowcenters): {len(windowcenters)}; len(windowwidths): {len(windowwidths)}\")\n","\n","\n","test_df[\"transfersyntaxuids\"] = transfersyntaxuids\n","test_df[\"jpeg2000s\"] = jpeg2000s\n","test_df[\"jpeglosslesss\"] = jpeglosslesss\n","test_df[\"photometricinterpretations\"] = photometricinterpretations\n","test_df[\"windowcenters\"] = windowcenters\n","test_df[\"windowwidths\"] = windowwidths\n","\n","\n","from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n","#### breast_birads\n","split = StratifiedGroupKFold(5)\n","for k, (_, test_idx) in enumerate(split.split(test_df, test_df.breast_birads, groups=test_df.study_id)):\n","    test_df.loc[test_idx, 'split'] = k\n","test_df.split = test_df.split.astype(int)\n","test_df[\"sample_rand\"] = np.random.rand(len(test_df)) \n","# test_df.loc[test_df[\"breast_birads\"]==1, \"sample_rand\"] = 0.0\n","\n","test_df[\"breast_birads\"] = test_df[\"breast_birads\"].apply(lambda x: x.replace(\"BI-RADS \", \"\"))\n","test_df[\"breast_birads\"] = test_df[\"breast_birads\"].astype(int)\n","test_df.to_csv(f'/home/br/workspace/RSNA2023/input/extra_data/vindr/vindr.csv', index=False)\n","\n","test_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["DATA_FOLDER = '../input/vindr/images'\n","test_df = pd.read_csv(\"../input/vindr/vindr.csv\")\n","test_df"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["SAVE_SIZE = int(IMG_SIZE * 1.125)\n","SAVE_FOLDER = f\"../input/images_gpugen/vindr_{IMG_SIZE}_{NBIT}bit_2/\"\n","os.makedirs(SAVE_FOLDER, exist_ok=True)\n","\n","N_CHUNKS = len(test_df[\"fns\"]) // 2000 if len(test_df[\"fns\"]) > 2000 else 1\n","CHUNKS = [(len(test_df[\"fns\"]) / N_CHUNKS * k, len(test_df[\"fns\"]) / N_CHUNKS * (k + 1)) for k in range(N_CHUNKS)]\n","CHUNKS = np.array(CHUNKS).astype(int)\n","JPG_FOLDER = f\"../input/images_gpugen/vindr_{IMG_SIZE}jpg/\"\n","os.makedirs(JPG_FOLDER, exist_ok=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## dicom process"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def convert_dicom_to_jpg(file, save_folder=\"\"):\n","    patient = file.split('/')[-2]\n","    image = file.split('/')[-1].replace('.dicom', '')\n","\n","    with open(file, 'rb') as fp:\n","        raw = DicomBytesIO(fp.read())\n","        ds = pydicom.dcmread(raw)\n","    offset = ds.PixelData.find(b\"\\x00\\x00\\x00\\x0C\")  #<---- the jpeg lossless header info we're looking for\n","    if offset == -1:\n","        return None\n","    hackedbitstream = bytearray()\n","    hackedbitstream.extend(ds.PixelData[offset:])\n","    with open(save_folder + f\"{patient}_{image}.jpg\", \"wb\") as binary_file:\n","        binary_file.write(hackedbitstream)\n","\n","\n","def process_dicom(img, dicom):\n","    try:\n","        invert = getattr(dicom, \"PhotometricInterpretation\", None) == \"MONOCHROME1\"\n","    except:\n","        invert = False\n","        \n","    center = parse_window_element(dicom[\"WindowCenter\"]) \n","    width = parse_window_element(dicom[\"WindowWidth\"])\n","        \n","    if (center is not None) & (width is not None):\n","        img = linear_window(img, center, width)\n","\n","    img = (img - img.min()) / (img.max() - img.min())\n","    if invert:\n","        img = 1 - img\n","    return img"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Vindr GPU"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# n_workers = 4\n","# for ttt, chunk in enumerate(CHUNKS):\n","#     print(f'chunk {ttt} of {len(CHUNKS)} chunks')\n","#     os.makedirs(JPG_FOLDER, exist_ok=True)\n","\n","#     _ = Parallel(n_jobs=n_workers)(\n","#         delayed(convert_dicom_to_jpg)(f'{DATA_FOLDER}/{img}', save_folder=JPG_FOLDER)\n","#         for img in test_df[\"fns\"].tolist()[chunk[0]: chunk[1]]\n","#     )\n","    \n","#     jpgfiles = glob.glob(JPG_FOLDER + \"*.jpg\")\n","#     print(f\"len(jpgfiles): {len(jpgfiles)}, {len(jpgfiles)/(chunk[1]-chunk[0])}\")\n","\n","#     pipe = jpg_decode_pipeline(jpgfiles, batch_size=1, num_threads=n_workers, device_id=0)\n","#     pipe.build()\n","\n","#     for i, f in enumerate(tqdm(jpgfiles)):\n","#         patient, dicom_id = f.split('/')[-1][:-4].split('_')\n","#         dicom = pydicom.dcmread(DATA_FOLDER + f\"/{patient}/{dicom_id}.dicom\")\n","#         try:\n","#             out = pipe.run()\n","#             # Dali -> Torch\n","#             img = out[0][0]\n","#             img_torch = torch.empty(img.shape(), dtype=torch.int16, device=\"cuda\")\n","#             feed_ndarray(img, img_torch, cuda_stream=torch.cuda.current_stream(device=0))\n","#             img = img_torch.float()\n","\n","#             #apply dicom preprocessing\n","#             img = process_dicom(img, dicom)\n","\n","#             #resize the torch image\n","#             img = F.interpolate(img.view(1, 1, img.size(0), img.size(1)), (SAVE_SIZE, SAVE_SIZE), mode=\"bilinear\")[0, 0]\n","\n","#             ####\n","#             if NBIT == 8:\n","#                 img = (img * 255).clip(0,255).to(torch.uint8).cpu().numpy() # 8 bit image\n","#             elif NBIT == 16:\n","#                 img = (img * 65535).clip(0,65535).cpu().numpy().astype(np.uint16) # 16 bit image\n","#             else:\n","#                 raise ValueError(f\"Unsupported NBIT value: {NBIT}\")\n","            \n","#             out_file_name = SAVE_FOLDER + f\"{patient}_{dicom_id}.png\"\n","#             cv2.imwrite(out_file_name, img)\n","    \n","#         except Exception as e:\n","#             print(i, e)\n","#             pipe = jpg_decode_pipeline(jpgfiles[i+1:], batch_size=1, num_threads=n_workers, device_id=0)\n","#             pipe.build()\n","#             continue\n","\n","#     shutil.rmtree(JPG_FOLDER)\n","    \n","# fns = glob.glob(f'{SAVE_FOLDER}/*.png')\n","# print(f'GPU Processed: {len(fns)}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Vindr CPU"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# gpu_processed_files = [fn.split('/')[-1].replace('_','/').replace('png','dcm') for fn in fns]\n","# to_process = [f for f in test_df[\"fns\"].values if f not in gpu_processed_files]\n","# print(f\"GPU processed files number: {len(gpu_processed_files)}, remain number: {len(to_process)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# def process(f, save_folder=\"\"):\n","#     patient = f.split('/')[-2]\n","#     dicom_id = f.split('/')[-1][:-4]\n","    \n","#     dicom = dicomsdl.open(f)\n","#     img = dicom.pixelData()\n","#     img = torch.from_numpy(img)\n","#     img = process_dicom(img, dicom)\n","    \n","#     img = F.interpolate(img.view(1, 1, img.size(0), img.size(1)), (SAVE_SIZE, SAVE_SIZE), mode=\"bilinear\")[0, 0]\n","\n","#     ####\n","#     if NBIT == 8:\n","#         img = (img * 255).clip(0,255).to(torch.uint8).cpu().numpy() # 8 bit image\n","#     elif NBIT == 16:\n","#         img = (img * 65535).clip(0,65535).cpu().numpy().astype(np.uint16) # 16 bit image\n","#     else:\n","#         raise ValueError(f\"Unsupported NBIT value: {NBIT}\")\n","\n","#     out_file_name = SAVE_FOLDER + f\"{patient}_{dicom_id}.png\"\n","#     cv2.imwrite(out_file_name, img)\n","#     return out_file_name"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# cpu_processed_filenames = Parallel(n_jobs=4)(\n","#     delayed(process)(f'{DATA_FOLDER}/{img}', save_folder=SAVE_FOLDER)\n","#     for img in tqdm(to_process)\n","# )\n","# cpu_processed_filenames = [f for f in cpu_processed_filenames if f]\n","# print(f'CPU Raw image load complete with {len(cpu_processed_filenames)} loaded')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# n_saved = len(glob.glob(f'{SAVE_FOLDER}/*.png'))\n","# print(f'Image on disk count : {n_saved}')\n","# print(f\"test_df length: {len(test_df)}\")\n","\n","# gc.collect()\n","# torch.cuda.empty_cache()\n","# assert n_saved == len(test_df) == 20000"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## cpu dicom"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def process_dicom(img, dicom):\n","    try:\n","        invert = getattr(dicom, \"PhotometricInterpretation\", None) == \"MONOCHROME1\"\n","    except:\n","        invert = False\n","        \n","    center = parse_window_element(dicom[\"WindowCenter\"]) \n","    width = parse_window_element(dicom[\"WindowWidth\"])\n","        \n","    if (center is not None) & (width is not None):\n","        img = linear_window(img, center, width)\n","\n","    img = (img - img.min()) / (img.max() - img.min())\n","    if invert:\n","        img = 1 - img\n","    return img\n","\n","def process2(f, size=SAVE_SIZE, data_folder=DATA_FOLDER, save_folder=SAVE_FOLDER):\n","    patient = f.split('/')[-2]\n","    dicom_id = f.split('/')[-1].replace('.dicom', '')\n","\n","\n","    dicom = dicomsdl.open(f\"{data_folder}/{f}\")\n","    img= dicom.pixelData()\n","    img = torch.from_numpy(img)\n","    img = process_dicom(img, dicom)\n","    img = F.interpolate(img.view(1, 1, img.size(0), img.size(1)), (size, size), mode=\"bilinear\")[0, 0]\n","\n","    if NBIT == 8:\n","        img = (img * 255).clip(0,255).to(torch.uint8).cpu().numpy()\n","    elif NBIT == 16:\n","        img = (img * 65535).clip(0,65535).cpu().numpy().astype(np.uint16)\n","    else:\n","        raise ValueError(f\"Unsupported NBIT value: {NBIT}\")\n","\n","    out_file_name = save_folder + f\"{patient}_{dicom_id}.png\"\n","    cv2.imwrite(out_file_name, img)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["_ = Parallel(n_jobs=5)(\n","    delayed(process2)(uid, size=SAVE_SIZE, data_folder=DATA_FOLDER, save_folder=SAVE_FOLDER)\n","    for uid in tqdm(test_df[\"fns\"])\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"py37","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"vscode":{"interpreter":{"hash":"d1f74254971ba6808fd145058d3af304d2496d72bd6eb4eea168933fe142b30a"}}},"nbformat":4,"nbformat_minor":4}
